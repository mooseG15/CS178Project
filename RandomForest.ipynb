{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodrigo Hernandez  \n",
    "Muzamil Syed  \n",
    "Mayra Gamboa  \n",
    "CS178  \n",
    "<h3 align='center'>Group Project</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<i><h2 align='center'>Introduction to Our Technique</h2></i>  \n",
    "The approach we will be taking will have to do with going into detail with Ensembles. \n",
    "We will each choose our own learning techniques and individually train on the provided data set.\n",
    "We will use multiple instances of each of our learners to store the ensemble???\n",
    "This will be done using existing packages provided by sklearn library. We will use the methods \n",
    "provided by the library and explore additional techniques to supplement these methods to vary the\n",
    "complexities of the models that result. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Questions\n",
    "Are we bagging (bootstrap) where we use part of the data?  \n",
    "To prevent overfitting we are using enhancement techniques for each our learners? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Report Format: (Maybe me we could have some kind of title page added to final pdf with our names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########Libraries Used Throughout The Code:##########\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import mltools as ml\n",
    "import mltools.dtree as dtree\n",
    "import mltools.logistic2 as lcs2\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "%matplotlib inline\n",
    "#Imported Library for Neural Network \n",
    "#Imported Library for Third Learner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########Imported Data:##########\n",
    "\n",
    "'''\n",
    "We will use the provided Class Kaggle Data in our class Kaggle Competition: CS178 Project 2016 \n",
    "\n",
    "https://inclass.kaggle.com/c/cs178-project-2016\n",
    "'''  \n",
    "\n",
    "# Get Kaggle training data\n",
    "X = np.genfromtxt(\"data/kaggle.X1.train.txt\",delimiter=\",\")\n",
    "Y = np.genfromtxt(\"data/kaggle.Y.train.txt\",delimiter=\",\")\n",
    "\n",
    "# also load features of the test data (to be predicted)\n",
    "Xe1 = np.genfromtxt(\"data/kaggle.X1.test.txt\",delimiter=\",\")\n",
    "\n",
    "perSplit = 0.8 # Percent at which to split the training data\n",
    "               # (e.g 0.8 = 80/20 split)\n",
    "\n",
    "Xtr,Xte,Ytr,Yte = ml.splitData(X,Y,0.8)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########Initialization of the Ensemble:##########\n",
    "\n",
    "'''\n",
    "We will start with an Ensemble of size 25...\n",
    "''' \n",
    "\n",
    "# Ensemble Variables\n",
    "size = 25  # the amount of learners in the ensemble\n",
    "features = 55 # the number of features to select from when bagging\n",
    "\n",
    "# Create the ensemble\n",
    "ensemble = [None] * size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########Code for the KNN Learner:##########\n",
    "from sklearn.neighbors import KNeighborsRegressor  #Imported Library for KNN Regressor \n",
    "\n",
    "'''\n",
    "KNN Learner INFO... \n",
    "-describe problem you use chose and methods to address it\n",
    "-how did you train the models?\n",
    "-how you selected any parameters each model/method requires \n",
    "-how they performed on test data\n",
    "-consider table of performance of different approaches or plots of perofrmance used to perform model selection\n",
    "''' \n",
    "\n",
    "'''\n",
    "Key Points:\n",
    "-Explore some aspect of prediction that we have not already done in depth \n",
    "-Identify a paper that proposes a method you think could be helpful \n",
    "-Use stacking/information from your leaderboard performance to try and improve your prediction quality \n",
    "-To explore approach: explore method from class fully enough to understand how changes might affect its performance,\n",
    "verify your findings make sense, and then use your findings to optimize performance\n",
    "-In Your Report: describe why you decided to explore this aspect, what you expected to find, and how your findings\n",
    "matched/ didnt match your expectations \n",
    "-Beware of the positive/negative aspects of the learners we discussed ie Nearest Neighbor methods can be powerful but can\n",
    "also be slow for large data sets...perhaps you can reduce the data in some way without sacrificing performance (bootstrap\n",
    "aggregation)\n",
    "-Linear methods may be fast but do not provide enough model complexity to provide a good fit so you may been to try and \n",
    "generate better features \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########Code for the Support Vector Machines:##########\n",
    "\n",
    "'''\n",
    "Support Vector Machine INFO... \n",
    "'''\n",
    "Xi,Yi = ml.utils.bootstrapData(Xtr,Ytr)\n",
    "clf = svm.SVR(kernel='poly',degree=2,cache_size=7000)\n",
    "#print(Xi.shape)\n",
    "\n",
    "A = Xi[0:30,0:55]\n",
    "B = Yi[0:30]\n",
    "print(Yi.shape)\n",
    "# SVMensemble = sklearn.ensemble.BaggingRegressor(clf,7,max_samples=25,\n",
    "#  max_features=features)\n",
    "\n",
    "clf.fit(A,B)\n",
    "print(clf.predict(Xte[0:2,0:55]))\n",
    "# SVMensemble.fit(Xtr,Ytr)\n",
    "# SVMensemble.predict(Xte[0,:])\n",
    "\n",
    "#Imported Library for Neural Network  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########Code for the Decision Tree:##########\n",
    "#Imported Library for Decision Trees   \n",
    "\n",
    "'''\n",
    "Decision Tree Learner INFO... \n",
    "'''\n",
    "\n",
    "# Decision Tree Variables\n",
    "depth = 20 # the maxth depth of the decision tree\n",
    "nodes = 8 # the minimum number of data to split node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########Code to store each learner in the ensemble:##########\n",
    "\n",
    "'''\n",
    "How should we store the learners we come up with? Since right now we have an ensemble of size 25 we could maybe \n",
    "create a list for each of our learners and bring them here then index each list of learners, train it and then store \n",
    "it into the ensemble before making all the predictions. What do you guys think?  \n",
    "'''\n",
    "# Create learners and add to ensemble\n",
    "\n",
    "for i in range(size):\n",
    "    \n",
    "    #for learners in each list \n",
    "    \n",
    "        #get KNN learner \n",
    "        #train KNN learner \n",
    "        #ensemble[i] = KNN Learner \n",
    "        \n",
    "        #get NN learner \n",
    "        #train NN learner \n",
    "        #ensemble[i] = NN Learner \n",
    "\n",
    "        #get DT learner \n",
    "        #train DT learner \n",
    "        #ensemble[i] = DT Learner \n",
    "        \n",
    "    #dt = dtree.treeRegress()\n",
    "    #Xi,Yi = ml.utils.bootstrapData(Xtr,Ytr)\n",
    "    #dt.train(Xi,Yi,maxdepth=depth,nFeatures=features,minParent=nodes)\n",
    "    \n",
    "    #ensemble[i] = dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########Code to output the predictions and evaluate them on kaggle:##########\n",
    "\n",
    "# Test correctness of ensemble through MSE\n",
    "mTest = Xte.shape[0] # Acquire the shape of the test data\n",
    "Yhat = np.zeros((mTest,num))\n",
    "MSE = 0\n",
    "\n",
    "for i in range(size):\n",
    "    Yhat[:,i] = ensemble[i].predict(Xte).reshape(mTest)\n",
    "    \n",
    "    Yhat = np.mean(Yhat,axis=1)\n",
    "    \n",
    "    MSE = np.mean((Yte - Yhat.reshape(Yte.shape))**2,axis=0)\n",
    "    \n",
    "print(MSE)\n",
    "\n",
    "'''\n",
    "Note:\n",
    "-Should not try to upload every possible model with every possible parameter setting \n",
    "-Use validation data, or cross-validation to assess which models are worth uploading, and just use the uploads\n",
    "to verify performance. \n",
    "'''\n",
    "#Ye = learner.predict( Xeval ); # make predictions\n",
    "# Note: be sure Ye is a flat vector, shape (m,)\n",
    "# otherwise, reshape it using e.g.\n",
    "# Ye = Ye.ravel()\n",
    "# or change the indexing in the code below:\n",
    "fh = open('predictions.csv','w') # open file for upload\n",
    "fh.write('ID,Prediction\\n') # output header line\n",
    "for i,yi in enumerate(Ye):\n",
    "fh.write('{},{}\\n'.format(i+1,yi)) # output each prediction\n",
    "fh.close() # close the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<i><h2 align='center'>Conclusion</h2></i>  \n",
    "Here we can probably summarize our results and the learners we were responsible for.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
